---
layout:     post
title:      Toxic Comment Classification Challenge - Kaggle 
date:       2020-04-29
tags: [kaggle, classification, sklearn]
categories: 
- machine learning
---

Task requirements: Build a multi-headed model that’s capable of detecting different types of of toxicity like *threats, obscenity, insults, and identity-based hate better* than Perspective’s current models. 

Full note on Github: [https://github.com/GaoangLiu/ipynb/blob/master/Toxic_Comment_Classification_Challenge_Kaggle.ipynb](https://github.com/GaoangLiu/ipynb/blob/master/Toxic_Comment_Classification_Challenge_Kaggle.ipynb)

